# import streamlit as st
# from openai import OpenAI

# # Show title and description.
# st.title("ğŸ“„ Document question answering")
# st.write(
#     "Upload a document below and ask a question about it â€“ GPT will answer! "
#     "To use this app, you need to provide an OpenAI API key, which you can get [here](https://platform.openai.com/account/api-keys). "
# )

# # Ask user for their OpenAI API key via `st.text_input`.
# # Alternatively, you can store the API key in `./.streamlit/secrets.toml` and access it
# # via `st.secrets`, see https://docs.streamlit.io/develop/concepts/connections/secrets-management
# openai_api_key = st.text_input("OpenAI API Key", type="password")
# if not openai_api_key:
#     st.info("Please add your OpenAI API key to continue.", icon="ğŸ—ï¸")
# else:

#     # Create an OpenAI client.
#     client = OpenAI(api_key=openai_api_key)

#     # Let the user upload a file via `st.file_uploader`.
#     uploaded_file = st.file_uploader(
#         "Upload a document (.txt or .md)", type=("txt", "md")
#     )

#     # Ask the user for a question via `st.text_area`.
#     question = st.text_area(
#         "Now ask a question about the document!",
#         placeholder="Can you give me a short summary?",
#         disabled=not uploaded_file,
#     )

#     if uploaded_file and question:

#         # Process the uploaded file and question.
#         document = uploaded_file.read().decode()
#         messages = [
#             {
#                 "role": "user",
#                 "content": f"Here's a document: {document} \n\n---\n\n {question}",
#             }
#         ]

#         # Generate an answer using the OpenAI API.
#         stream = client.chat.completions.create(
#             model="gpt-3.5-turbo",
#             messages=messages,
#             stream=True,
#         )

#         # Stream the response to the app using `st.write_stream`.
#         st.write_stream(stream)


import streamlit as st
from mood_llm import get_prompts
from openai import OpenAI
import time
from mood_llm import generate_custom_file_path
from mood_llm import get_file_paths
from mood_llm import extract_number_from_file_path
from mood_llm import get_final_prompt
import os

# é…ç½®OpenAIå®¢æˆ·ç«¯
client = OpenAI(base_url="https://dashscope.aliyuncs.com/compatible-mode/v1", api_key="sk-86a9b469ca3447e3ab60f6858591e7bf", timeout=100)


# é»˜è®¤çš„ä»»åŠ¡prompt
default_prompt = "è¯·æ ¹æ®ç»™å®šçš„å…³é”®è¯ç”Ÿæˆç›¸åº”çš„ä»»åŠ¡"

# é¡µé¢æ ‡é¢˜
st.title("èˆ†æƒ…åˆ†æPOC")

# é€‰æ‹©å…³é”®è¯
keyword = st.selectbox("é€‰æ‹©ä¸€ä¸ªéœ€è¦èˆ†æƒ…åˆ†æçš„å¯¹è±¡", ["æ­å·å·çƒŸå‚","çƒŸè‰",  "é¦™çƒŸ", "æµ™æ±Ÿä¸­çƒŸ"])

# é»˜è®¤ä»»åŠ¡prompt
default_prompt = """é»˜è®¤çš„ä»»åŠ¡ï¼šæ‰¾å‡ºæ‰€æœ‰ç›´æ¥é’ˆå¯¹ {keyword} çš„è´Ÿé¢ æˆ–è€… æ­£é¢çš„å¸–å­æˆ–è€…è¯„è®º,
åªæ˜¯ç›¸å…³ä¸ç®—ç›´æ¥é’ˆå¯¹ã€‚æŒ‰ç…§ è½¬å‘æ•°+è¯„è®ºæ•°+ç‚¹èµæ•°æ€»å’Œ  æˆ–è€… å½±å“æ•° æ’åºï¼Œ
å¹¶ä¸”æŒ‰ç…§è´Ÿé¢å’Œæ­£é¢æ’åºã€‚æœ€ååŸºäºè¿™äº› {keyword} çš„ç›¸å…³çš„å¸–å­å’Œè¯„è®ºï¼Œ
å†™ä¸€ä¸ªç»¼è¿°ï¼Œæ¦‚æ‹¬å¤§ä¼—å¯¹äº {keyword} çš„å°è±¡ï¼Œèˆ†è®ºï¼š"""

# æ˜¾ç¤ºé»˜è®¤ä»»åŠ¡promptï¼Œæµ…ç°è‰²
st.markdown(f'<p style="color:grey;">{default_prompt.format(keyword=keyword)}</p>', unsafe_allow_html=True)

# ç”¨æˆ·è¾“å…¥è‡ªå®šä¹‰ä»»åŠ¡
user_prompt = st.text_area("å¦‚æœä½ å¯¹äºé»˜è®¤çš„ä»»åŠ¡ä¸æ»¡æ„ï¼Œå¯ä»¥è¾“å…¥è‡ªå®šä¹‰ä»»åŠ¡ï¼š", default_prompt.format(keyword=keyword), height=200)


# åˆ›å»ºä¸€ä¸ªæŒ‰é’®ï¼Œç”¨æˆ·ç‚¹å‡»åç¡®è®¤è¾“å…¥
if st.button("ç¡®è®¤"):
    # å¦‚æœç”¨æˆ·è¾“å…¥äº†è‡ªå®šä¹‰ä»»åŠ¡ï¼Œåˆ™è¦†ç›–é»˜è®¤ä»»åŠ¡
    final_prompt = user_prompt if user_prompt != default_prompt.format(keyword=keyword) else default_prompt.format(keyword=keyword)



    # # ç”¨æˆ·è¾“å…¥è‡ªå®šä¹‰ä»»åŠ¡prompt
    # user_prompt = st.text_area("è¾“å…¥è‡ªå®šä¹‰ä»»åŠ¡", "", help="å¦‚æœä¸è¾“å…¥ï¼Œè‡ªå®šä¹‰ä»»åŠ¡å°†ä¼šè¦†ç›–é»˜è®¤ä»»åŠ¡")

    # # åˆ¤æ–­æ˜¯å¦æœ‰è‡ªå®šä¹‰ä»»åŠ¡
    # final_prompt = user_prompt if user_prompt else default_prompt

    # æ˜¾ç¤ºå½“å‰é€‰æ‹©çš„ä»»åŠ¡prompt
    #st.write(f"æœ€ç»ˆä»»åŠ¡æç¤º: {final_prompt}")

    # æµå¼è¾“å‡ºç»“æœ
    #st.write("æ­£åœ¨ç”Ÿæˆä»»åŠ¡...")
    # è¿™é‡Œä½ å¯ä»¥è°ƒç”¨ä½ çš„ç®—æ³•é€»è¾‘å¤„ç†`keyword`å’Œ`final_prompt`ï¼Œç„¶åè¾“å‡ºç»“æœ
    st.write(f"æœ€ç»ˆä»»åŠ¡ï¼š{final_prompt} \n\n\n é’ˆå¯¹å…³é”®è¯: {keyword} çš„ç”Ÿæˆç»“æœï¼š")
    print("final_prompt:",final_prompt)
    print("keyword:",keyword)

    prompts = get_prompts(final_prompt,keyword)

    page_no =0
    for prompt in prompts:
        page_no +=1
        messages = [{"role": "user", "content": prompt}]
        response = client.chat.completions.create(
            model="deepseek-r1-distill-qwen-32b",
            messages=messages,
            stream=True
        )

        # åˆå§‹åŒ–Streamlitçš„æµå¼è¾“å‡º
        #st.title("æ­£åœ¨ç”Ÿæˆç»“æœ...")
        response_placeholder = st.empty()  # ç”¨äºå®æ—¶è¾“å‡ºç»“æœ

        # åˆå§‹åŒ–å˜é‡
        reasoning_content = ""
        content = ""
        with st.spinner(f"æ­£åœ¨ç­›é€‰å¾®åšæœç´¢ {keyword} ç¬¬{page_no}é¡µ çš„ç›¸å…³å†…å®¹..."):
            with st.empty():
                #st.write(f"æ­£åœ¨ç­›é€‰å¾®åšæœç´¢ {keyword} ç¬¬{page_no}é¡µ çš„ç›¸å…³å†…å®¹...")
                # æµå¼è¾“å‡ºéƒ¨åˆ†
                for chunk in response:
                    # å¤„ç†æ¨ç†å†…å®¹
                    if chunk.choices[0].delta.reasoning_content:
                        reasoning_content += chunk.choices[0].delta.reasoning_content
                        response_placeholder.markdown(f"**æ¨ç†è¿‡ç¨‹ï¼š**\n{reasoning_content}")
                    
                    # å¤„ç†ç”Ÿæˆå†…å®¹
                    if chunk.choices[0].delta.content:
                        content += chunk.choices[0].delta.content
                        response_placeholder.markdown(f"**ç”Ÿæˆå†…å®¹ï¼š**\n{content}")

                    time.sleep(0.1)

            response_placeholder.empty()  # ç”¨äºå®æ—¶è¾“å‡ºç»“æœ

        st.empty()  # æ¸…é™¤ä¹‹å‰çš„è¾“å‡º





            
        files_paths = get_file_paths(keyword)
        file_path = files_paths[0]
        p = extract_number_from_file_path(file_path)
        file_path = generate_custom_file_path(file_path, f"temp_{keyword}_{p}.txt")

        with open(file_path, 'w', encoding='utf-8') as temp_file:
            temp_file.write(content)


    final_prompt_full = get_final_prompt(final_prompt, keyword,pages="all",time_range="all")

    
    # åˆ›å»ºæ¶ˆæ¯ç»“æ„
    messages = [{"role": "user", "content": final_prompt_full}]

    # è¿›è¡ŒOpenAI APIè¯·æ±‚å¹¶å¼€å¯æµå¼è¾“å‡º
    response = client.chat.completions.create(
        model="deepseek-r1-distill-qwen-32b",
        messages=messages,
        stream=True
    )

    # åˆå§‹åŒ–Streamlitçš„æµå¼è¾“å‡º
    st.title("ä¿¡æ¯ç­›é€‰å®Œæˆï¼Œç»¼åˆåˆ†æå…¨éƒ¨ç›¸å…³ä¿¡æ¯çš„æœ€ç»ˆç»“æœï¼š")
    response_placeholder = st.empty()  # ç”¨äºå®æ—¶è¾“å‡ºç»“æœ

    # åˆå§‹åŒ–å˜é‡
    reasoning_content = ""
    content = ""

    with st.empty():
        # æµå¼è¾“å‡ºéƒ¨åˆ†
        for chunk in response:
            # å¤„ç†æ¨ç†å†…å®¹
            if chunk.choices[0].delta.reasoning_content:
                reasoning_content += chunk.choices[0].delta.reasoning_content
                response_placeholder.markdown(f"**æ¨ç†è¿‡ç¨‹ï¼š**\n{reasoning_content}")
            
            # å¤„ç†ç”Ÿæˆå†…å®¹
            if chunk.choices[0].delta.content:
                content += chunk.choices[0].delta.content
                response_placeholder.markdown(f"**ç”Ÿæˆå†…å®¹ï¼š**\n{content}")

            time.sleep(0.1)

    response_placeholder.empty()  # ç”¨äºå®æ—¶è¾“å‡ºç»“æœ

    # å½“æ¨ç†å†…å®¹æµå¼è¾“å‡ºå®Œæˆåï¼Œåœç•™åœ¨é¡µé¢ä¸Š
    if reasoning_content:
        st.markdown(f"**æœ€ç»ˆæ¨ç†è¿‡ç¨‹ï¼š**\n{reasoning_content}")

    # å½“ç”Ÿæˆå†…å®¹æµå¼è¾“å‡ºå®Œæˆåï¼Œåœç•™åœ¨é¡µé¢ä¸Š
    if content:
        st.markdown(f"**æœ€ç»ˆç”Ÿæˆå†…å®¹ï¼š**\n{content}")


    filtered_file_path = files_paths[0]
    print(filtered_file_path)
    def get_folder_path(file_path):
        """
        ä»æ–‡ä»¶è·¯å¾„ä¸­æå–æ‰€åœ¨æ–‡ä»¶å¤¹çš„ç›¸å¯¹è·¯å¾„ã€‚
        
        :param file_path: str, æ–‡ä»¶çš„ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„
        :return: str, æ–‡ä»¶å¤¹çš„ç›¸å¯¹è·¯å¾„
        """
        return os.path.dirname(file_path)
    
    folder_path = get_folder_path(filtered_file_path)
    print("folder_path:",folder_path)
    temp_full_file_path = os.path.join("data", keyword, f"temp_{keyword}_full.txt")
    print("temp_full_file_path:", temp_full_file_path)
    
    if os.path.exists(temp_full_file_path):
        with open(temp_full_file_path, 'r', encoding='utf-8') as file:
            full_content = file.read()
            print("full_content:",full_content)
            st.markdown(f"<h2>ç›¸å…³çš„å¾®åšå¸–å­åŸæ–‡ï¼š</h2>\n{full_content}", unsafe_allow_html=True)
    else:
        st.error("æœªæ‰¾åˆ°æ–‡ä»¶ temp_{keyword}_full.txt")


    



